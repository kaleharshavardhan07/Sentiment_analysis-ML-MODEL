{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "pip install numpy pandas scikit-learn nltk\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bfihEWWt118g",
        "outputId": "f55c6ec1-0962-46f8-a90b-8c91d3df620e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (1.26.4)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (3.9.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk) (8.1.8)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk) (4.67.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "file_path = \"/content/train.csv\"\n",
        "\n",
        "df = pd.read_csv(file_path, encoding=\"latin-1\")\n",
        "print(df.head())\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UHSczgwH3x3g",
        "outputId": "824c53a2-4a4c-437e-bcef-14924e9cdc6e"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       textID                                               text  \\\n",
            "0  cb774db0d1                I`d have responded, if I were going   \n",
            "1  549e992a42      Sooo SAD I will miss you here in San Diego!!!   \n",
            "2  088c60f138                          my boss is bullying me...   \n",
            "3  9642c003ef                     what interview! leave me alone   \n",
            "4  358bd9e861   Sons of ****, why couldn`t they put them on t...   \n",
            "\n",
            "                         selected_text sentiment Time of Tweet Age of User  \\\n",
            "0  I`d have responded, if I were going   neutral       morning        0-20   \n",
            "1                             Sooo SAD  negative          noon       21-30   \n",
            "2                          bullying me  negative         night       31-45   \n",
            "3                       leave me alone  negative       morning       46-60   \n",
            "4                        Sons of ****,  negative          noon       60-70   \n",
            "\n",
            "       Country  Population -2020  Land Area (Km²)  Density (P/Km²)  \n",
            "0  Afghanistan          38928346         652860.0               60  \n",
            "1      Albania           2877797          27400.0              105  \n",
            "2      Algeria          43851044        2381740.0               18  \n",
            "3      Andorra             77265            470.0              164  \n",
            "4       Angola          32866272        1246700.0               26  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "filtered_df = df[['text', 'sentiment']]\n",
        "print(filtered_df.head())\n",
        "df=filtered_df\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LM-0lEku5NGt",
        "outputId": "bbc64bc6-2b5c-4c06-9049-635772d61eb4"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                text sentiment\n",
            "0                I`d have responded, if I were going   neutral\n",
            "1      Sooo SAD I will miss you here in San Diego!!!  negative\n",
            "2                          my boss is bullying me...  negative\n",
            "3                     what interview! leave me alone  negative\n",
            "4   Sons of ****, why couldn`t they put them on t...  negative\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "sentiment_counts = df['sentiment'].value_counts()\n",
        "print(sentiment_counts)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TL8K-qfaZOGL",
        "outputId": "97acfe63-7279-4ef3-a25d-d8b1962ddd09"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sentiment\n",
            "neutral     11118\n",
            "positive     8582\n",
            "negative     7781\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.utils import resample\n",
        "\n",
        "positive = df[df['sentiment'] == \"positive\"]\n",
        "neutral = df[df['sentiment'] == \"neutral\"]\n",
        "negative = df[df['sentiment'] == \"negative\"]\n",
        "\n",
        "\n",
        "max_size= max(len(positive),len(negative),len(neutral))\n",
        "\n",
        "\n",
        "positive_balanced = resample(positive, replace=True, n_samples=max_size, random_state=42)\n",
        "neutral_balanced = resample(neutral, replace=True, n_samples=max_size, random_state=42)\n",
        "negative_balanced = resample(negative, replace=True, n_samples=max_size, random_state=42)\n",
        "\n",
        "df_balanced = pd.concat([positive_balanced, neutral_balanced, negative_balanced])\n"
      ],
      "metadata": {
        "id": "08T-7iUxaBsf"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "sentiment_counts = df_balanced['sentiment'].value_counts()\n",
        "\n",
        "\n",
        "print(sentiment_counts)\n",
        "\n",
        "df=df_balanced"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bHeTtGPtaYbE",
        "outputId": "8ace3e97-a71f-4bbb-a9f2-e372e52523b9"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sentiment\n",
            "positive    11118\n",
            "neutral     11118\n",
            "negative    11118\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize"
      ],
      "metadata": {
        "id": "lGtbyqZx5Mtu"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download(\"stopwords\")\n",
        "nltk.download(\"punkt\")\n",
        "nltk.download('punkt_tab')\n",
        "\n",
        "def clean_text(text):\n",
        "  text=re.sub(r\"http\\S+|www\\S+|https\\S+\",\"\",text,flags=re.MULTILINE)\n",
        "  text = re.sub(r\"@\\w+|#\\w+\", \"\", text)\n",
        "  text = re.sub(r\"[^\\w\\s]\", \"\", text)\n",
        "  text = text.lower()\n",
        "  return text\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lgFXwOct5m3D",
        "outputId": "f5623c7b-0a10-4fe5-844c-4db74d900514"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stop_words=set(stopwords.words(\"english\"))\n",
        "def preprocess_text(text):\n",
        "    if not isinstance(text, str):\n",
        "        text = \"\"\n",
        "\n",
        "    text = clean_text(text)\n",
        "    tokens = word_tokenize(text)\n",
        "    tokens = [word for word in tokens if word.lower() not in stop_words]  # Case insensitive\n",
        "    return \" \".join(tokens)\n",
        "\n",
        "df[\"cleaned_text\"] = df[\"text\"].apply(preprocess_text)\n",
        "\n",
        "def map_sentiment(value):\n",
        "    if value == \"positive\":\n",
        "        return 1\n",
        "    elif value == \"neutral\":\n",
        "        return 0\n",
        "    elif value == \"negative\":\n",
        "        return -1\n",
        "    else:\n",
        "        return None\n",
        "\n",
        "df[\"sentiment\"] = df[\"sentiment\"].apply(map_sentiment)\n"
      ],
      "metadata": {
        "id": "ljx8Ok0w6uXb"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print (df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n0K6tPjh83WI",
        "outputId": "ee67c65c-144a-41f3-e748-52172a951874"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                    text  sentiment  \\\n",
            "23091  grinning like a Cheshire cat.... ....happy as ...          1   \n",
            "2666   Got the sniffles   I SO don`t want to get sick...          1   \n",
            "17190  havent been on here in ages  sorry twitter.. t...          1   \n",
            "16540   Yes Hindustan Rocks dude! Dunia mein asay koi...          1   \n",
            "18192                      _anderson hehe   fun tweets !          1   \n",
            "\n",
            "                                            cleaned_text  \n",
            "23091     grinning like cheshire cat happy hell made day  \n",
            "2666           got sniffles dont want get sick dont need  \n",
            "17190         havent ages sorry twitter tweetdeck broken  \n",
            "16540  yes hindustan rocks dude dunia mein asay koi f...  \n",
            "18192                          _anderson hehe fun tweets  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "tfidf=TfidfVectorizer(max_features=5000)\n",
        "X = tfidf.fit_transform(df[\"cleaned_text\"]).toarray()\n",
        "y = df[\"sentiment\"].values\n",
        "\n",
        "print( df.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fDKoBf859FZp",
        "outputId": "ec2b73df-d5f6-4eb9-e2e4-e96ce1ee3f20"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                    text  sentiment  \\\n",
            "23091  grinning like a Cheshire cat.... ....happy as ...          1   \n",
            "2666   Got the sniffles   I SO don`t want to get sick...          1   \n",
            "17190  havent been on here in ages  sorry twitter.. t...          1   \n",
            "16540   Yes Hindustan Rocks dude! Dunia mein asay koi...          1   \n",
            "18192                      _anderson hehe   fun tweets !          1   \n",
            "\n",
            "                                            cleaned_text  \n",
            "23091     grinning like cheshire cat happy hell made day  \n",
            "2666           got sniffles dont want get sick dont need  \n",
            "17190         havent ages sorry twitter tweetdeck broken  \n",
            "16540  yes hindustan rocks dude dunia mein asay koi f...  \n",
            "18192                          _anderson hehe fun tweets  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "vectorizer = CountVectorizer(max_features=5000)\n",
        "X = vectorizer.fit_transform(df[\"cleaned_text\"]).toarray()\n",
        "y = df[\"sentiment\"].values\n",
        "\n",
        "print( df.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SvbuHR3o9mUp",
        "outputId": "875e33d2-75aa-49c1-c2ea-cce6a46efe9b"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                    text  sentiment  \\\n",
            "23091  grinning like a Cheshire cat.... ....happy as ...          1   \n",
            "2666   Got the sniffles   I SO don`t want to get sick...          1   \n",
            "17190  havent been on here in ages  sorry twitter.. t...          1   \n",
            "16540   Yes Hindustan Rocks dude! Dunia mein asay koi...          1   \n",
            "18192                      _anderson hehe   fun tweets !          1   \n",
            "\n",
            "                                            cleaned_text  \n",
            "23091     grinning like cheshire cat happy hell made day  \n",
            "2666           got sniffles dont want get sick dont need  \n",
            "17190         havent ages sorry twitter tweetdeck broken  \n",
            "16540  yes hindustan rocks dude dunia mein asay koi f...  \n",
            "18192                          _anderson hehe fun tweets  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "aGdS-tsc914Q"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "#logistic regression\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zujZ-Unw-IN5",
        "outputId": "b9c8f534-b032-4a90-b1a4-d8533da1b832"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.7868385549392894\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.81      0.78      0.79      2221\n",
            "           0       0.72      0.76      0.74      2232\n",
            "           1       0.84      0.83      0.83      2218\n",
            "\n",
            "    accuracy                           0.79      6671\n",
            "   macro avg       0.79      0.79      0.79      6671\n",
            "weighted avg       0.79      0.79      0.79      6671\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "\n",
        "#naive bayes\n",
        "model = MultinomialNB()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KFP2XCoDCBNs",
        "outputId": "08ecec75-96a0-4682-c48a-dd640e2436ea"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.7103882476390346\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.73      0.76      0.75      2221\n",
            "           0       0.64      0.60      0.62      2232\n",
            "           1       0.75      0.78      0.76      2218\n",
            "\n",
            "    accuracy                           0.71      6671\n",
            "   macro avg       0.71      0.71      0.71      6671\n",
            "weighted avg       0.71      0.71      0.71      6671\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "\n",
        "# SVM\n",
        "model = SVC(kernel=\"linear\")\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(classification_report(y_test, y_pred))\n"
      ],
      "metadata": {
        "id": "Qz6MUwHZCI6g"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}