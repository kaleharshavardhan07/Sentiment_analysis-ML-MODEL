# -*- coding: utf-8 -*-
"""Untitled0.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1iKXJzW6zzXtTrsAK-gYotxIxQh9SWmpo
"""


import pandas as pd

file_path = "/content/train.csv"

df = pd.read_csv(file_path, encoding="latin-1")
print(df.head())

filtered_df = df[['text', 'sentiment']]
print(filtered_df.head())
df=filtered_df

sentiment_counts = df['sentiment'].value_counts()
print(sentiment_counts)

from sklearn.utils import resample

positive = df[df['sentiment'] == "positive"]
neutral = df[df['sentiment'] == "neutral"]
negative = df[df['sentiment'] == "negative"]


max_size= max(len(positive),len(negative),len(neutral))


positive_balanced = resample(positive, replace=True, n_samples=max_size, random_state=42)
neutral_balanced = resample(neutral, replace=True, n_samples=max_size, random_state=42)
negative_balanced = resample(negative, replace=True, n_samples=max_size, random_state=42)

df_balanced = pd.concat([positive_balanced, neutral_balanced, negative_balanced])

sentiment_counts = df_balanced['sentiment'].value_counts()


print(sentiment_counts)

df=df_balanced

import re
from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize

import nltk
nltk.download("stopwords")
nltk.download("punkt")
nltk.download('punkt_tab')

def clean_text(text):
  text=re.sub(r"http\S+|www\S+|https\S+","",text,flags=re.MULTILINE)
  text = re.sub(r"@\w+|#\w+", "", text)
  text = re.sub(r"[^\w\s]", "", text)
  text = text.lower()
  return text

stop_words=set(stopwords.words("english"))
def preprocess_text(text):
    if not isinstance(text, str):
        text = ""

    text = clean_text(text)
    tokens = word_tokenize(text)
    tokens = [word for word in tokens if word.lower() not in stop_words]  # Case insensitive
    return " ".join(tokens)

df["cleaned_text"] = df["text"].apply(preprocess_text)

def map_sentiment(value):
    if value == "positive":
        return 1
    elif value == "neutral":
        return 0
    elif value == "negative":
        return -1
    else:
        return None

df["sentiment"] = df["sentiment"].apply(map_sentiment)

print (df.head())

from sklearn.feature_extraction.text import TfidfVectorizer

tfidf=TfidfVectorizer(max_features=5000)
X = tfidf.fit_transform(df["cleaned_text"]).toarray()
y = df["sentiment"].values

print( df.head())

from sklearn.feature_extraction.text import CountVectorizer

vectorizer = CountVectorizer(max_features=5000)
X = vectorizer.fit_transform(df["cleaned_text"]).toarray()
y = df["sentiment"].values

print( df.head())

from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, classification_report
#logistic regression
model = LogisticRegression()
model.fit(X_train, y_train)

y_pred = model.predict(X_test)
print("Accuracy:", accuracy_score(y_test, y_pred))
print(classification_report(y_test, y_pred))

from sklearn.naive_bayes import MultinomialNB

#naive bayes
model = MultinomialNB()
model.fit(X_train, y_train)


y_pred = model.predict(X_test)
print("Accuracy:", accuracy_score(y_test, y_pred))
print(classification_report(y_test, y_pred))

from sklearn.svm import SVC

# SVM
model = SVC(kernel="linear")
model.fit(X_train, y_train)

y_pred = model.predict(X_test)
print("Accuracy:", accuracy_score(y_test, y_pred))
print(classification_report(y_test, y_pred))